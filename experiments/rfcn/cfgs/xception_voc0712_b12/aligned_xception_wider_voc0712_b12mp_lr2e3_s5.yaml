---
MXNET_VERSION: "mxnet_f2b1ee4"
output_path: "./output/rfcn/xception_voc"
symbol: aligned_xception_wider_b12_withmp_nbins
gpus: '0,1,2,3'
CLASS_AGNOSTIC: true
SCALES:
- 600
- 1000
default:
  frequent: 20
  kvstore: device
network:
  pretrained: "./model/pretrained_model/aligned_xception_wider224_082"
  pretrained_epoch: 0
  PIXEL_MEANS:
  - 103.06
  - 115.90
  - 123.15
  IMAGE_STRIDE: 0
  RCNN_FEAT_STRIDE: 16
  RPN_FEAT_STRIDE: 16
  FIXED_PARAMS:
  - block1_
  - convolution2d_1
  - block2_
  - batchnormalization
  - gamma
  - beta
  FIXED_PARAMS_SHARED:
  - block1_
  - block2_
  - block3_
  - block4_
  - block5_
  - block6_
  - block7_
  - block8_
  - block9_
  - block10_
  - block11_
  - block12_
  - convolution2d_1
  - convolution2d_2
  - convolution2d_3
  - batchnormalization
  - gamma
  - beta
  ANCHOR_RATIOS:
  - 0.5
  - 1
  - 2
  ANCHOR_SCALES:
  - 8
  - 16
  - 32
  NUM_ANCHORS: 9
  RGB_MODEL: 0
  RPN_LOSS_SCALE: 0.2
  RCNN_LOSS_SCALE: 1
  CONVNEW_LR_MULT: 1
dataset:
  NUM_CLASSES: 21
  dataset: PascalVOC
  dataset_path: "./data/VOCdevkit"
  image_set: 2007_trainval+2012_trainval
  root_path: "./data/"
  test_image_set: 2007_test
  proposal: rpn
TRAIN:
  lr: 0.002
  lr_step: '5'
  lr_factor: 0.1
  wd: 0.0001
  warmup: true
  warmup_lr: 0.0002
  ALTERNATE:
          RPN_BATCH_IMAGES: 1
          RCNN_BATCH_IMAGES: 1
          rpn1_lr: 0.002
          rpn1_lr_step: '2'    # recommend '2'
          rpn1_epoch: 3       # recommend 3
          rfcn1_lr: 0.005
          rfcn1_lr_step: '5'   # recommend '5'
          rfcn1_epoch: 8      # recommend 8
          rpn2_lr: 0.002
          rpn2_lr_step: '2'    # recommend '2'
          rpn2_epoch: 3       # recommend 3
          rfcn2_lr: 0.005
          rfcn2_lr_step: '5'   # recommend '5'
          rfcn2_epoch: 8      # recommend 8
          # optional
          rpn3_lr: 0.002
          rpn3_lr_step: '2'    # recommend '2'
          rpn3_epoch: 3       # recommend 3

  # typically we will use 4000 warmup step for single GPU
  warmup_step: 1000
  begin_epoch: 0
  end_epoch: 8
  model_prefix: 'rfcn_voc'
  # whether resume training
  RESUME: false
  # whether flip image
  FLIP: true
  # whether shuffle image
  SHUFFLE: true
  # whether use OHEM
  ENABLE_OHEM: true
  # size of images for each device, 2 for rcnn, 1 for rpn and e2e
  BATCH_IMAGES: 1
  # e2e changes behavior of anchor loader and metric
  END2END: true
  # group images with similar aspect ratio
  ASPECT_GROUPING: true
  # R-CNN
  # rcnn rois batch size
  BATCH_ROIS: -1
  BATCH_ROIS_OHEM: 128
  # rcnn rois sampling params
  FG_FRACTION: 0.25
  FG_THRESH: 0.5
  BG_THRESH_HI: 0.5
  BG_THRESH_LO: 0.0
  # rcnn bounding box regression params
  BBOX_REGRESSION_THRESH: 0.5
  BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0

  # RPN anchor loader
  # rpn anchors batch size
  RPN_BATCH_SIZE: 256
  # rpn anchors sampling params
  RPN_FG_FRACTION: 0.5
  RPN_POSITIVE_OVERLAP: 0.7
  RPN_NEGATIVE_OVERLAP: 0.3
  RPN_CLOBBER_POSITIVES: false
  # rpn bounding box regression params
  RPN_BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  RPN_POSITIVE_WEIGHT: -1.0
  # used for end2end training
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 6000
  RPN_POST_NMS_TOP_N: 300
  RPN_MIN_SIZE: 0
  # approximate bounding box regression
  BBOX_NORMALIZATION_PRECOMPUTED: true
  BBOX_MEANS:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  BBOX_STDS:
  - 0.1
  - 0.1
  - 0.2
  - 0.2
TEST:
  # use rpn to generate proposal
  HAS_RPN: true
  # size of images for each device
  BATCH_IMAGES: 1
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 6000
  RPN_POST_NMS_TOP_N: 300
  RPN_MIN_SIZE: 0
  # RPN generate proposal
  PROPOSAL_NMS_THRESH: 0.7
  PROPOSAL_PRE_NMS_TOP_N: 20000
  PROPOSAL_POST_NMS_TOP_N: 2000
  PROPOSAL_MIN_SIZE: 0
  # RCNN nms
  NMS: 0.3
  test_epoch: 8
  EVAL_EVERY_EPOCH: true
